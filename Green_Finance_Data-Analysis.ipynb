{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "688139a2",
   "metadata": {},
   "source": [
    "# Question 1: Conditional Statements (If-Else) and Arithmetic Operations \n",
    "### Description: The government seeks to identify PLTS projects with high CO2 reduction efficiency per unit of investment, calculated as CO2 reduction per million rupiah.\n",
    "### Task:\n",
    "### • Merge Environmental_Dataset.xlsx and Financial_Dataset.xlsx using Project_ID.\n",
    "### • For PLTS projects (Project_ID starts with \"PLTS\"), compute the ratio: CO2_Reduction / (Investment_Cost * 1_000_000).\n",
    "### • Use if-else to classify the ratio as \"High\" (≥ 0.5 tons CO2e/million Rp) or \"Low\"(< 0.5).\n",
    "### • Display results as: \"Project_ID: Ratio (Category)\" using f-strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3abc2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLTS-JABW-001: 0.0004318181818181818 (Low)\n",
      "PLTS-JATIM-001: 0.0004494830944413924 (Low)\n",
      "PLTS-NTB-001: 0.00044444444444444447 (Low)\n",
      "PLTS-NTT-001: 0.0005 (Low)\n",
      "PLTS-SULS-001: 0.00047808764940239046 (Low)\n"
     ]
    }
   ],
   "source": [
    "# import pandas ibrary\n",
    "import pandas as pd\n",
    "\n",
    "# read the Environmental_Dataset\n",
    "df_Env = pd.read_excel('Data/Environmental_Dataset.xlsx')\n",
    "\n",
    "# read the Financial_Dataset\n",
    "df_Fin = pd.read_excel('Data/Financial_Dataset.xlsx')\n",
    "\n",
    "# merge the datasets by Project_Id field and merge all the columns\n",
    "df_merged = pd.merge( df_Env, df_Fin, on='Project_ID', how='outer' )\n",
    "\n",
    "# call the row to use\n",
    "for index, row in df_merged.iterrows():\n",
    "\n",
    "    # calculate the CO2 reduction efficiency per million investment the PLTS Project\n",
    "    if row['Project_ID'].startswith('PLTS'):\n",
    "        ratio = (row['CO2_Reduction']) / (row['Investment_Cost'] * 1000000)\n",
    "\n",
    "        # print the ratio category\n",
    "        if ratio >= 0.5:\n",
    "            print(f'{row['Project_ID']}: {ratio} (High)')\n",
    "        else:\n",
    "            print(f'{row['Project_ID']}: {ratio} (Low)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53712f43",
   "metadata": {},
   "source": [
    "# Question 2: For Loop and Lists\n",
    "### Description: The government needs the average CO2 reduction across PLTM projects to assess their collective environmental impact.\n",
    "### Task:\n",
    "### • Use Environmental_Dataset.xlsx.\n",
    "### • Create a list of CO2_Reduction values for PLTM projects (Project_ID starts with \"PLTM\").\n",
    "### • Use a for loop to calculate the total CO2 reduction and count of PLTM projects.\n",
    "### • Compute and display the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a5e13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average CO2 Reduction for PLTM Projects:34600.0 tons CO2e\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df_Env = pd.read_excel('Data/Environmental_Dataset.xlsx')\n",
    "\n",
    "# make list CO_Reduction\n",
    "PLTM_CO2_Red_List = []\n",
    "\n",
    "for index, row in df_Env.iterrows():\n",
    "    Project_ID = row['Project_ID']\n",
    "    CO2_Reduction = row ['CO2_Reduction']\n",
    "\n",
    "    # make list value Project_ID starts with \"PLTM\"\n",
    "    if isinstance(Project_ID, str) and Project_ID.startswith(\"PLTM\"):\n",
    "        PLTM_CO2_Red_List.append(CO2_Reduction)\n",
    "    \n",
    "# calculate the average\n",
    "total_CO2_reduction = 0\n",
    "count_CO2_reduction = 0\n",
    "for CO2_Reduction_Value in PLTM_CO2_Red_List:\n",
    "    total_CO2_reduction += CO2_Reduction_Value\n",
    "    count_CO2_reduction += 1\n",
    "    average_CO2_reduction = total_CO2_reduction / count_CO2_reduction\n",
    "\n",
    "# print the average\n",
    "print(f\"Average CO2 Reduction for PLTM Projects:{average_CO2_reduction} tons CO2e\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f169d3a",
   "metadata": {},
   "source": [
    "# Question 3: While Loop and User Input\n",
    "### Description: The government requires a tool to check land status and social conflict levels by entering Project_IDs.\n",
    "### Task:\n",
    "#### • Use Social_Dataset.xlsx.\n",
    "#### • Write a program using a while loop to prompt for Project_ID until \"DONE\" is entered.\n",
    "#### • For valid Project_IDs, display Land_Status and Tingkat_Konflik.\n",
    "#### • For invalid Project_IDs, show \"Project not found\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98b1cdb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLTS-NTT-001 - Land Status: Adat - Tingkat Konflik: High: ⚠️⚠️⚠️\n",
      "Project 'PLTS-BALI-001' not found.\n",
      "Done, goodbye!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df_Soc = pd.read_excel('Data/Social_Dataset.xlsx')\n",
    "\n",
    "# Make a dictionary to store project data for quick lookup\n",
    "social_data_dict = {}\n",
    "\n",
    "# Populate the dictionary from the DataFrame\n",
    "for index, row in df_Soc.iterrows():\n",
    "    # Ensure Project_ID is stripped, converted to string, and uppercase for consistent lookup\n",
    "    project_id = row['Project_ID']\n",
    "    social_data_dict[project_id] = {\n",
    "        # Use consistent key names for dictionary access (matching the DataFrame column names)\n",
    "        'Land_Status': row['Land_Status'],\n",
    "        'Tingkat_Konflik': row['Tingkat_Konflik']\n",
    "    }\n",
    "\n",
    "# Start the while loop to continuously prompt for Project_ID\n",
    "while True:\n",
    "    # Get input from the user\n",
    "    # This makes the input case-insensitive for 'DONE' and Project_IDs\n",
    "    project_id_input = input(\"\\nEnter Project_ID (or DONE to finish): \").strip().upper()\n",
    "    # Check if the user wants to exit\n",
    "    if project_id_input == \"DONE\":\n",
    "        print(\"Done, goodbye!\")\n",
    "        break # Exit the while loop\n",
    "\n",
    "    # Check if the entered Project_ID exists in the dictionary\n",
    "    # Corrected: Use social_data_dict for lookup, not Project_ID variable\n",
    "    if project_id_input in social_data_dict:\n",
    "        # Retrieve the Land_Status and Tingkat_Konflik from the dictionary\n",
    "        # Corrected: Access data from social_data_dict\n",
    "        data = social_data_dict[project_id_input]\n",
    "        land_status = data[\"Land_Status\"]\n",
    "        tingkat_konflik = data[\"Tingkat_Konflik\"]\n",
    "\n",
    "        # Display the retrieved information\n",
    "        print(f\"{project_id_input} - Land Status: {land_status} - Tingkat Konflik: {tingkat_konflik}\")\n",
    "    else:\n",
    "        # Inform the user if the Project_ID is not found\n",
    "        print(f\"Project '{project_id_input}' not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9a17f1",
   "metadata": {},
   "source": [
    "# Question 4: Dictionary and Conditional Filtering\n",
    "### Description: The government seeks projects with high investment attractiveness and low social conflict to minimise risks.\n",
    "### Task:\n",
    "#### • Merge Economic_Dataset.xlsx and Social_Dataset.xlsx using Project_ID.\n",
    "#### • Create a dictionary with Project_ID as keys and a tuple (Daya_Tarik_Investasi,Tingkat_Konflik) as values.\n",
    "#### • Use a for loop with if to filter projects where Daya_Tarik_Investasi == \"High\" and Tingkat_Konflik == \"Low\".\n",
    "#### • Display the filtered Project_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceb43864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Projects with High Investment Attractiveness and Low Social Conflict:\n",
      "- PLTM-SUMUT-001\n",
      "- PLTS-JATIM-001\n",
      "- PLTS-NTB-001\n",
      "- PLTS-JABW-001\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "df_econ = pd.read_excel('Data/Economic_Dataset.xlsx')\n",
    "df_soc = pd.read_excel('Data/Social_Dataset.xlsx')\n",
    "\n",
    "# Merge the two DataFrames on 'Project_ID'\n",
    "# A 'left' merge ensures all projects from the economic dataset are considered,\n",
    "# and social data is added if available.\n",
    "# 'inner' merge would only include projects present in BOTH datasets.\n",
    "merged_df = pd.merge(df_econ, df_soc, on='Project_ID', how='inner')\n",
    "# Create a dictionary with Project_ID as keys and (Daya_Tarik_Investasi, Tingkat_Konflik) as values\n",
    "project_attractiveness_conflict = {}\n",
    "for index, row in merged_df.iterrows():\n",
    "    project_id = row['Project_ID']\n",
    "    daya_tarik_investasi = row['Daya_Tarik_Investasi']\n",
    "    tingkat_konflik = row['Tingkat_Konflik']\n",
    "    project_attractiveness_conflict[project_id] = (daya_tarik_investasi, tingkat_konflik)\n",
    "\n",
    "# List to store filtered Project_IDs\n",
    "filtered_project_ids = []\n",
    "\n",
    "# Filter projects where Daya_Tarik_Investasi == \"High\" and Tingkat_Konflik == \"Low\"\n",
    "for project_id, (daya_tarik, tingkat_konflik) in project_attractiveness_conflict.items():\n",
    "    if daya_tarik.startswith(\"High\") and tingkat_konflik.startswith(\"Low\"):\n",
    "        filtered_project_ids.append(project_id)\n",
    "# Display the filtered Project_IDs\n",
    "if filtered_project_ids:\n",
    "    print(\"\\nProjects with High Investment Attractiveness and Low Social Conflict:\")\n",
    "    for project_id in filtered_project_ids:\n",
    "        print(f\"- {project_id}\")\n",
    "else:\n",
    "    print(\"\\nNo projects found matching the criteria (High Investment Attractiveness and Low Social Conflict).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a787d1a4",
   "metadata": {},
   "source": [
    "# Question 5: Functions and Arithmetic\n",
    "### Description: The government needs to calculate the total investment for projects with high location efficiency.\n",
    "### Task:\n",
    "#### • Define a function calculate_total_investment that takes a list of Project_IDs and merged data from Geospatial_Dataset.xlsx and Financial_Dataset.xlsx.\n",
    "#### • Use a for loop to sum Investment_Cost for projects where Efisiensi_Lokasi == \"High\".\n",
    "#### • Return and display the total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9696e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Investment for Projects with High Location Efficiency: 955.73 billion rupiah\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the new datasets\n",
    "df_geo = pd.read_excel('Data/Geospatial_Dataset.xlsx')\n",
    "df_fin = pd.read_excel('Data/Financial_Dataset.xlsx')\n",
    "\n",
    "# Merge the geospatial and financial DataFrames on 'Project_ID'\n",
    "# An 'inner' merge is used to ensure we only consider projects present in both datasets\n",
    "merged_df_geo_fin = pd.merge(df_geo, df_fin, on='Project_ID', how='inner')\n",
    "\n",
    "def calculate_total_investment(merged_df_geo_fin) -> float:\n",
    "    total_investment = 0.0\n",
    "    high_efficiency_projects_found = False\n",
    "\n",
    "    # Iterate through the rows of the merged DataFrame\n",
    "    for index, row in merged_df_geo_fin.iterrows():\n",
    "        # Ensure 'Efisiensi_Lokasi' is treated as a string and stripped for comparison\n",
    "        efficiency = str(row['Efisiensi_Lokasi']).strip()\n",
    "        \n",
    "        # Ensure 'Investment_Cost' is a numeric type for summation\n",
    "        # 'errors='coerce'' will turn non-numeric values into NaN\n",
    "        investment_cost = pd.to_numeric(row['Investment_Cost'], errors='coerce')\n",
    "\n",
    "        # Check if Efisiensi_Lokasi is \"High\" and Investment_Cost is a valid number\n",
    "        if efficiency.startswith(\"High\"):\n",
    "            total_investment += investment_cost\n",
    "            high_efficiency_projects_found = True\n",
    "\n",
    "    if not high_efficiency_projects_found:\n",
    "        print(\"No projects with 'High' location efficiency found in the dataset for investment calculation.\")\n",
    "\n",
    "    return total_investment\n",
    "\n",
    "# Calculate the total investment for projects with high location efficiency\n",
    "total_investment_high_efficiency = calculate_total_investment(merged_df_geo_fin)\n",
    "\n",
    "# Display the total investment\n",
    "print(f\"\\nTotal Investment for Projects with High Location Efficiency: {total_investment_high_efficiency} billion rupiah\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73bddc3",
   "metadata": {},
   "source": [
    "# Question 6: Modules and Error Handling\n",
    "### Description: The government requires a reusable tool to compute CO2 reduction efficiency with error handling.\n",
    "### Task:\n",
    "#### • Create a module green_analysis.py with a function compute_co2_efficiency that takes CO2_Reduction and Investment_Cost as parameters.\n",
    "#### • Use try-except to handle ZeroDivisionError (if Investment_Cost is 0), returning \"Cannot compute\" if an error occurs.\n",
    "#### • Otherwise, compute and return the ratio: CO2_Reduction / (Investment_Cost * 1_000_000).\n",
    "#### • In the main script, import the module and test it on three projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e816518d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Projects selected for testing (including synthetic cases):\n",
      "  PLTS-NTT-001: CO2_Reduction=75000, Investment_Cost=150.0\n",
      "  PLTM-SUMUT-001: CO2_Reduction=30000, Investment_Cost=80.0\n",
      "  PLTS-JATIM-001: CO2_Reduction=90000, Investment_Cost=200.23\n",
      "  TEST_ZERO_INV: CO2_Reduction=100000.0, Investment_Cost=0.0\n",
      "  TEST_INVALID_INV: CO2_Reduction=50000.0, Investment_Cost=N/A\n",
      "  TEST_NEGATIVE_CO2: CO2_Reduction=-10000.0, Investment_Cost=50000.0\n",
      "\n",
      "--- Testing CO2 Efficiency for Selected Projects ---\n",
      "\n",
      "Testing PLTS-NTT-001 (CO2 Red: 75000, Inv Cost: 150.0):\n",
      "  CO2 Reduction Efficiency: 0.0005000000\n",
      "\n",
      "Testing PLTM-SUMUT-001 (CO2 Red: 30000, Inv Cost: 80.0):\n",
      "  CO2 Reduction Efficiency: 0.0003750000\n",
      "\n",
      "Testing PLTS-JATIM-001 (CO2 Red: 90000, Inv Cost: 200.23):\n",
      "  CO2 Reduction Efficiency: 0.0004494831\n",
      "\n",
      "Testing TEST_ZERO_INV (CO2 Red: 100000.0, Inv Cost: 0.0):\n",
      "  CO2 Reduction Efficiency: Cannot compute: Investment Cost is zero.\n",
      "\n",
      "Testing TEST_INVALID_INV (CO2 Red: 50000.0, Inv Cost: N/A):\n",
      "  CO2 Reduction Efficiency: Cannot compute: Invalid Investment Cost (not a number).\n",
      "\n",
      "Testing TEST_NEGATIVE_CO2 (CO2 Red: -10000.0, Inv Cost: 50000.0):\n",
      "  CO2 Reduction Efficiency: -0.0000002000\n"
     ]
    }
   ],
   "source": [
    "from green_analysis import compute_co2_efficiency\n",
    "import pandas as pd\n",
    "\n",
    "# load dataset\n",
    "df_env = pd.read_excel('Data/Environmental_Dataset.xlsx')\n",
    "df_fin = pd.read_excel('Data/Financial_Dataset.xlsx')\n",
    "\n",
    "# Merge the two DataFrames on 'Project_ID'\n",
    "# Use an 'inner' merge to ensure we only consider projects present in both datasets\n",
    "merged_projects_df = pd.merge(df_env, df_fin, on='Project_ID', how='inner')\n",
    "\n",
    "# Create a dictionary with Project_ID as keys and (CO2_Reduction, Investment_Cost) as values\n",
    "# This will be used to test the compute_co2_efficiency function\n",
    "projects_for_testing = {}\n",
    "selected_projects_df = merged_projects_df.head(3) \n",
    "\n",
    "for index, row in selected_projects_df.iterrows():\n",
    "    project_id = str(row['Project_ID']).strip().upper() # Standardize Project_ID\n",
    "    co2_reduction = row['CO2_Reduction']\n",
    "    investment_cost = row['Investment_Cost']\n",
    "    projects_for_testing[project_id] = (co2_reduction, investment_cost)\n",
    "\n",
    "# Add synthetic projects for testing the error handling\n",
    "projects_for_testing[\"TEST_ZERO_INV\"] = (100000.0, 0.0)\n",
    "projects_for_testing[\"TEST_INVALID_INV\"] = (50000.0, \"N/A\")\n",
    "projects_for_testing[\"TEST_NEGATIVE_CO2\"] = (-10000.0, 50000.0) # Added for new error handling test\n",
    "\n",
    "print(\"\\nProjects selected for testing (including synthetic cases):\")\n",
    "for project_id, data in projects_for_testing.items():\n",
    "    print(f\"  {project_id}: CO2_Reduction={data[0]}, Investment_Cost={data[1]}\")\n",
    "\n",
    "# Iterate through the created dictionary and test the function for each project\n",
    "if not projects_for_testing:\n",
    "    print(\"\\nNo projects available for testing after merging datasets and selection.\")\n",
    "else:\n",
    "    print(\"\\n--- Testing CO2 Efficiency for Selected Projects ---\")\n",
    "    for project_id, (co2_red, inv_cost) in projects_for_testing.items():\n",
    "        print(f\"\\nTesting {project_id} (CO2 Red: {co2_red}, Inv Cost: {inv_cost}):\")\n",
    "        efficiency = compute_co2_efficiency(co2_red, inv_cost)\n",
    "\n",
    "        # Format output based on whether the result is a float or a string (error message)\n",
    "        if isinstance(efficiency, float):\n",
    "            print(f\"  CO2 Reduction Efficiency: {efficiency:.10f}\")\n",
    "        else:\n",
    "            print(f\"  CO2 Reduction Efficiency: {efficiency}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693cd387",
   "metadata": {},
   "source": [
    "# Question 7: Error Handling in Loops\n",
    "### Description: The government needs to calculate the average energy output of selected projects, handling missing data.\n",
    "### Task:\n",
    "#### • Create a list of Project_IDs to analyse.\n",
    "#### • Use a for loop with try-except to process Energy_Output from Environmental_Dataset.xlsx, catching KeyError for missing Project_IDs.\n",
    "#### • Sum valid Energy_Output values and count valid projects.\n",
    "#### • Compute and display the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2854a20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing energy output for selected projects:\n",
      "\n",
      "Project ID 'PLTS-NTT-001': Energy Output = 25000\n",
      "Project ID 'PLTM-SUMUT-001': Energy Output = 10000\n",
      "Project ID 'PLTS-JATIM-001': Energy Output = 30000\n",
      "Project ID 'PLTM-KALB-001': Energy Output = 12000\n",
      "Project ID 'PLTS-SULS-001': Energy Output = 20000\n",
      "Project ID 'PLTM-PAPU-001': Energy Output = 15000\n",
      "Project ID 'PLTS-NTB-001': Energy Output = 28000\n",
      "Project ID 'PLTM-ACHD-001': Energy Output = 11000\n",
      "Project ID 'PLTS-JABW-001': Energy Output = 32000\n",
      "Project ID 'PLTM-SULU-001': Energy Output = 13000\n",
      "\n",
      "--- Summary ---\n",
      "Total valid energy output: 196000 kWh\n",
      "Number of valid projects processed: 10\n",
      "Average energy output: 19600.0 kWh\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load dataset\n",
    "df_Env = pd.read_excel('Data/Environmental_Dataset.xlsx')\n",
    "\n",
    "# create a list of Project_ID\n",
    "Project_ID_List = []\n",
    "\n",
    "for index, row in df_Env.iterrows():\n",
    "    Project_ID = row['Project_ID']\n",
    "    Project_ID_List.append(Project_ID)\n",
    "\n",
    "\n",
    "# Make first value for iteration\n",
    "total_energy_output = 0\n",
    "valid_projects_count = 0\n",
    "missing_projects = []\n",
    "invalid_outputs = []\n",
    "\n",
    "print(\"Processing energy output for selected projects:\\n\")\n",
    "\n",
    "# Use a for loop with try-except to process Energy_Output\n",
    "for project_id in Project_ID_List:\n",
    "    try:\n",
    "        # Attempt to find the project ID in the DataFrame\n",
    "        # Use .loc for more explicit row and column selection\n",
    "        # This will return a Series if found, or an empty Series if not\n",
    "        project_row = df_Env.loc[df_Env['Project_ID'] == project_id]\n",
    "\n",
    "        if not project_row.empty:\n",
    "            # Project ID found, now get the energy output\n",
    "            energy_output = project_row['Energy_Output'].iloc[0] # .iloc[0] to get the scalar value\n",
    "\n",
    "            # Check for NaN values (missing data within existing projects)\n",
    "            if pd.isna(energy_output):\n",
    "                print(f\"Warning: Project ID '{project_id}' found, but has missing (NaN) energy output. Skipping.\")\n",
    "                invalid_outputs.append(project_id)\n",
    "                continue # Skip to the next project in the loop\n",
    "            else:\n",
    "                total_energy_output += energy_output\n",
    "                valid_projects_count += 1\n",
    "                print(f\"Project ID '{project_id}': Energy Output = {energy_output}\")\n",
    "        else:\n",
    "            # Project ID not found in the DataFrame\n",
    "            print(f\"Error: Project ID '{project_id}' not found in the dataset. Skipping.\")\n",
    "            missing_projects.append(project_id)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Catch any other unexpected errors during processing\n",
    "        print(f\"An unexpected error occurred for Project ID '{project_id}': {e}. Skipping.\")\n",
    "\n",
    "print(\"\\n--- Summary ---\")\n",
    "\n",
    "# Compute and display the average.\n",
    "if valid_projects_count > 0:\n",
    "    average_energy_output = total_energy_output / valid_projects_count\n",
    "    print(f\"Total valid energy output: {total_energy_output} kWh\")\n",
    "    print(f\"Number of valid projects processed: {valid_projects_count}\")\n",
    "    print(f\"Average energy output: {average_energy_output} kWh\")\n",
    "else:\n",
    "    print(\"No valid projects were processed to calculate an average.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63678d58",
   "metadata": {},
   "source": [
    "# Bonus Question: Machine Learning/AI with Decision Tree\n",
    "### Description: The government aims to predict investment attractiveness (\"High\", \"Medium\", \"Low\") for new projects based on features like GDP_Growth, CO2_Reduction, and Investment_Cost.\n",
    "### Task:\n",
    "#### • Merge Economic_Dataset.xlsx, Environmental_Dataset.xlsx, and Financial_Dataset.xlsx\n",
    "#### • Use scikit-learn to build a Decision Tree Classifier with Daya_Tarik_Investasi as the target.\n",
    "#### • Train the model, evaluate its accuracy, and predict the attractiveness of a new project (e.g., GDP_Growth=5.0, CO2_Reduction=70000, Investment_Cost=150)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a197ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Data Head:\n",
      "        Project_ID  GDP_Growth  Interest_Rate  Bond_Yield  \\\n",
      "0    PLTS-NTT-001         4.5            4.2         5.1   \n",
      "1  PLTM-SUMUT-001         5.2            3.8         4.8   \n",
      "2  PLTS-JATIM-001         6.0            0.0         5.0   \n",
      "3   PLTM-KALB-001         4.8            4.1         5.2   \n",
      "4   PLTS-SULS-001         5.5            0.0         4.9   \n",
      "\n",
      "                               Konteks_Ekonomi Daya_Tarik_Investasi  \\\n",
      "0  Sumba: pertumbuhan rendah, pariwisata hijau          Medium: 💵💵💵   \n",
      "1               Tapanuli: ekonomi agro, stabil           High: 💵💵💵💵   \n",
      "2         Surabaya: pasar besar, industri kuat          High: 💵💵💵💵💵   \n",
      "3    Kalbar: ekonomi perkebunan, sedang tumbuh          Medium: 💵💵💵   \n",
      "4     Makassar: hub ekonomi, pendidikan tinggi           High: 💵💵💵💵   \n",
      "\n",
      "   CO2_Reduction  Energy_Output  Environmental_Risk_Index  \\\n",
      "0          75000          25000                        45   \n",
      "1          30000          10000                        60   \n",
      "2          90000          30000                        30   \n",
      "3          35000          12000                        55   \n",
      "4          60000          20000                        40   \n",
      "\n",
      "                                 Konteks_Lingkungan Peringkat_Dampak  \\\n",
      "0  Sumba: radiasi matahari tinggi, rawan kekeringan       High: 🌿🌿🌿🌿   \n",
      "1        Tapanuli: banjir musiman, debit air stabil      Medium: 🌿🌿🌿   \n",
      "2         Surabaya: risiko rendah, efisiensi tinggi      High: 🌿🌿🌿🌿🌿   \n",
      "3         Kalbar: rawan banjir, hutan lindung dekat      Medium: 🌿🌿🌿   \n",
      "4             Makassar: cuaca stabil, risiko sedang       High: 🌿🌿🌿🌿   \n",
      "\n",
      "   Investment_Cost  Revenue_Stream  Debt_Ratio  Payment_Delay  \\\n",
      "0           150.00            12.5        0.65             30   \n",
      "1            80.00             6.8        0.55             15   \n",
      "2           200.23            18.0        0.70             45   \n",
      "3            90.00             7.2        0.60             20   \n",
      "4           125.50            10.0        0.50             10   \n",
      "\n",
      "                                      Konteks_Proyek    Status_Rank  \n",
      "0  PLTS di Sumba, biaya logistik tinggi, pendanaa...  Medium: ★★★☆☆  \n",
      "1      PLTM di Tapanuli, akses mudah ke jaringan PLN     Low: ★★☆☆☆  \n",
      "2    PLTS besar di Surabaya, permintaan pasar tinggi    High: ★★★★☆  \n",
      "3     PLTM di Kalimantan Barat, tantangan lahan adat  Medium: ★★★☆☆  \n",
      "4      PLTS di Makassar, efisiensi tinggi distribusi     Low: ★☆☆☆☆  \n",
      "\n",
      "Merged Data Info:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 17 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Project_ID                10 non-null     object \n",
      " 1   GDP_Growth                10 non-null     float64\n",
      " 2   Interest_Rate             10 non-null     float64\n",
      " 3   Bond_Yield                10 non-null     float64\n",
      " 4   Konteks_Ekonomi           10 non-null     object \n",
      " 5   Daya_Tarik_Investasi      10 non-null     object \n",
      " 6   CO2_Reduction             10 non-null     int64  \n",
      " 7   Energy_Output             10 non-null     int64  \n",
      " 8   Environmental_Risk_Index  10 non-null     int64  \n",
      " 9   Konteks_Lingkungan        10 non-null     object \n",
      " 10  Peringkat_Dampak          10 non-null     object \n",
      " 11  Investment_Cost           10 non-null     float64\n",
      " 12  Revenue_Stream            10 non-null     float64\n",
      " 13  Debt_Ratio                10 non-null     float64\n",
      " 14  Payment_Delay             10 non-null     int64  \n",
      " 15  Konteks_Proyek            10 non-null     object \n",
      " 16  Status_Rank               10 non-null     object \n",
      "dtypes: float64(6), int64(4), object(7)\n",
      "memory usage: 1.5+ KB\n",
      "\n",
      "LabelEncoder classes (numerical mapping): ['High: 💵💵💵💵', 'High: 💵💵💵💵💵', 'Low: 💵💵', 'Medium: 💵💵💵']\n",
      "Example of encoded target values:\n",
      "  Daya_Tarik_Investasi  Daya_Tarik_Investasi_Encoded\n",
      "0          Medium: 💵💵💵                             3\n",
      "1           High: 💵💵💵💵                             0\n",
      "2          High: 💵💵💵💵💵                             1\n",
      "3          Medium: 💵💵💵                             3\n",
      "4           High: 💵💵💵💵                             0\n",
      "\n",
      "Warning: Could not use stratify due to small class sizes or single instance class. Splitting without stratification. Error: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.\n",
      "\n",
      "Training set shape (X_train): (8, 3)\n",
      "Testing set shape (X_test): (2, 3)\n",
      "Training target distribution:\n",
      "Daya_Tarik_Investasi_Encoded\n",
      "3    0.500\n",
      "0    0.250\n",
      "2    0.125\n",
      "1    0.125\n",
      "Name: proportion, dtype: float64\n",
      "Testing target distribution:\n",
      "Daya_Tarik_Investasi_Encoded\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Decision Tree Classifier trained successfully.\n",
      "\n",
      "Model Accuracy on Test Set: 0.50\n",
      "\n",
      "Features of new project for prediction: {'GDP_Growth': 5.0, 'CO2_Reduction': 70000.0, 'Investment_Cost': 150.0}\n",
      "Predicted Investment Attractiveness: Medium: 💵💵💵\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df_econ = pd.read_excel('Data/Economic_Dataset.xlsx')\n",
    "df_env = pd.read_excel('Data/Environmental_Dataset.xlsx')\n",
    "df_fin = pd.read_excel('Data/Financial_Dataset.xlsx')\n",
    "\n",
    "merged_df = pd.merge(df_econ, df_env, on='Project_ID', how='inner')\n",
    "merged_df = pd.merge(merged_df, df_fin, on='Project_ID', how='inner')\n",
    "\n",
    "print(\"Merged Data Head:\\n\", merged_df.head())\n",
    "print(\"\\nMerged Data Info:\\n\")\n",
    "merged_df.info()\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "features = ['GDP_Growth', 'CO2_Reduction', 'Investment_Cost']\n",
    "target = 'Daya_Tarik_Investasi'\n",
    "\n",
    "# Select relevant columns and drop rows with any missing values in these columns\n",
    "# This ensures a clean dataset for model training.\n",
    "df_ml = merged_df[features + [target]].dropna()\n",
    "\n",
    "# Encode the categorical target variable ('High', 'Medium', 'Low') into numerical format.\n",
    "# LabelEncoder assigns numerical labels alphabetically by default.\n",
    "# For example: High=0, Low=1, Medium=2\n",
    "le = LabelEncoder()\n",
    "df_ml['Daya_Tarik_Investasi_Encoded'] = le.fit_transform(df_ml[target])\n",
    "\n",
    "print(f\"\\nLabelEncoder classes (numerical mapping): {list(le.classes_)}\")\n",
    "print(f\"Example of encoded target values:\\n{df_ml[[target, 'Daya_Tarik_Investasi_Encoded']].head()}\")\n",
    "\n",
    "X = df_ml[features]\n",
    "y = df_ml['Daya_Tarik_Investasi_Encoded']\n",
    "\n",
    "# Splitting: Use train_test_split to divide data into training (80%) and testing (20%) sets.\n",
    "# random_state ensures reproducibility of the split.\n",
    "# stratify=y ensures that the proportion of target classes is maintained in both train and test sets,\n",
    "# which is important for imbalanced datasets.\n",
    "try:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "except ValueError as e:\n",
    "    # This might occur if one of the classes has too few samples to be split proportionally\n",
    "    print(f\"\\nWarning: Could not use stratify due to small class sizes or single instance class. Splitting without stratification. Error: {e}\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(f\"\\nTraining set shape (X_train): {X_train.shape}\")\n",
    "print(f\"Testing set shape (X_test): {X_test.shape}\")\n",
    "print(f\"Training target distribution:\\n{pd.Series(y_train).value_counts(normalize=True)}\")\n",
    "print(f\"Testing target distribution:\\n{pd.Series(y_test).value_counts(normalize=True)}\")\n",
    "\n",
    "\n",
    "# 3. Training: Fit the Decision Tree model using the training data.\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42) # random_state for reproducibility\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nDecision Tree Classifier trained successfully.\")\n",
    "\n",
    "# 4. Evaluation: Compute accuracy on the test set using accuracy_score.\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nModel Accuracy on Test Set: {accuracy:.2f}\")\n",
    "\n",
    "# 5. Prediction: Predict the class for new data.\n",
    "new_project_data = pd.DataFrame([{\n",
    "    'GDP_Growth': 5.0,\n",
    "    'CO2_Reduction': 70000,\n",
    "    'Investment_Cost': 150\n",
    "}])\n",
    "\n",
    "# Predict the encoded label for the new project\n",
    "predicted_attractiveness_encoded = dt_classifier.predict(new_project_data)\n",
    "\n",
    "# Inverse transform the encoded label to get the original categorical label\n",
    "predicted_attractiveness = le.inverse_transform(predicted_attractiveness_encoded)\n",
    "\n",
    "print(f\"\\nFeatures of new project for prediction: {new_project_data.iloc[0].to_dict()}\")\n",
    "print(f\"Predicted Investment Attractiveness: {predicted_attractiveness[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "energi_hijau",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
